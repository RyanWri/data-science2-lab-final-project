{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Data Science 2 - final project results - team 11: Barack Samuni & Barak Yaakov\n",
    "***"
   ],
   "id": "f9ecbf1a8d0d2cfd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T11:21:31.284625Z",
     "start_time": "2024-09-28T11:21:31.280931Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from src.team_11.task7.task7 import extract_hebrew_content\n",
    "from task7.task7 import translate_dataframe"
   ],
   "id": "c9b440a01ab8da1c",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Task 7: Data cleaning and completion for table: hospitalization2\n",
    "***"
   ],
   "id": "43c2fd1dffdd822d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T11:21:32.489014Z",
     "start_time": "2024-09-28T11:21:31.295635Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# ========== Path Config ==========\n",
    "# The data is present in the data folder two directories up\n",
    "data_dir = os.path.abspath(os.path.join(os.getcwd(),\"..\",\"data\"))\n",
    "load_path = os.path.join(data_dir, \"rehospitalization.xlsx\")\n",
    "sheet = 'hospitalization2'\n",
    "export_path = fr'task7\\{sheet}_Team_11.csv'\n",
    "\n",
    "\n",
    "# =========== Helper Functions ===========\n",
    "\n",
    "def fill_na_with_other_col(df, col_to_fill, col_reference, fill_val=-1, reference_val=-2):\n",
    "    \"\"\"\n",
    "    Fills missing values in col_to_fill with values from col_reference based on conditions.\n",
    "    \"\"\"\n",
    "    mask_fill = (df[col_to_fill] == fill_val) & (df[col_reference] != reference_val)\n",
    "    df.loc[mask_fill, col_to_fill] = df.loc[mask_fill, col_reference]\n",
    "\n",
    "def fill_missing_doctors(df, diagnosis_col, doctor_map):\n",
    "    \"\"\"\n",
    "    Fills missing doctors based on the most frequent diagnosis association.\n",
    "    \"\"\"\n",
    "    mask = (df['Releasing_Doctor'] == -1) & (df[diagnosis_col] != -1)\n",
    "    df.loc[mask, 'Releasing_Doctor'] = df.loc[mask, diagnosis_col].map(lambda diag: doctor_map.get(get_diag(diag), -1))\n",
    "\n",
    "def get_diag_categories(df):\n",
    "    \"\"\"\n",
    "    Returns unique diagnosis categories for rows with missing doctors.\n",
    "    \"\"\"\n",
    "    diagnoses = df.loc[df['Releasing_Doctor'] == -1, ['Diagnosis_In_Reception', 'Diagnosis_In_Release']]\n",
    "    all_diags = pd.concat([diagnoses['Diagnosis_In_Release'], diagnoses['Diagnosis_In_Reception']])\n",
    "    cats = set(get_diag(diag) for diag in all_diags if diag != -1)\n",
    "    return list(cats)\n",
    "\n",
    "def get_diag(diag):\n",
    "    # Convert to string and split by comma, stripping spaces from each part\n",
    "    split_diag = [part.strip() for part in str(diag).split(',') if part.strip()]\n",
    "    # Return the first non-empty value or None if the list is empty\n",
    "    return split_diag[0] if split_diag else None\n",
    "\n",
    "# A function that translates the contents of a column in a DataFrame according to a given dictionary\n",
    "def translate_column(df, translations_dict, column_name):\n",
    "    for i in range(len(df[column_name])):\n",
    "        df.loc[i, column_name] = translations_dict[df[column_name][i]]\n",
    "        \n",
    "def calculate_optimal_split(df, column_name, number_of_quartiles):\n",
    "    quantiles = np.linspace(0, 100, number_of_quartiles + 1)\n",
    "    quartiles = np.percentile(df[column_name], quantiles)\n",
    "    bin_edges = [df[column_name].min()] + list(quartiles[1:-1]) + [df[column_name].max()]\n",
    "    return bin_edges\n",
    "\n",
    "# =========== Dataset loading & Initial Fix ===========\n",
    "df = pd.read_excel(load_path, sheet_name=sheet)\n",
    "initial_row_count = df.shape[0]  # Record the initial number of rows\n",
    "\n",
    "# Check for null values before cleaning\n",
    "print(f'Total samples before cleaning: {initial_row_count}\\n')\n",
    "print(\"Null values before cleaning:\\n\")\n",
    "df.isnull().sum()"
   ],
   "id": "9b3ffdf83cf313aa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples before cleaning: 8917\n",
      "\n",
      "Null values before cleaning:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Patient                         0\n",
       "unitName1                       0\n",
       "Admission_Medical_Record        0\n",
       "Admission_Entry_Date            0\n",
       "Release_Date                    0\n",
       "unitName2                       0\n",
       "Admission_Medical_Record2       0\n",
       "Admission_Entry_Date2           0\n",
       "Release_Date2                   0\n",
       "סוג קבלה                       68\n",
       "מהיכן המטופל הגיע               0\n",
       "Release_Type                    0\n",
       "רופא משחרר                     88\n",
       "ימי אשפוז                       0\n",
       "אבחנות בקבלה                  802\n",
       "אבחנות בשחרור                 233\n",
       "מחלקות מייעצות               4176\n",
       "ct                              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T11:21:34.811206Z",
     "start_time": "2024-09-28T11:21:32.533343Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df.rename(columns={'סוג קבלה': 'Entry_Type', 'מהיכן המטופל הגיע': 'Patient_Origin', \n",
    "                   'רופא משחרר': 'Releasing_Doctor', 'ימי אשפוז': 'Admission_Days2', \n",
    "                   'אבחנות בקבלה': 'Diagnosis_In_Reception', 'אבחנות בשחרור': 'Diagnosis_In_Release', \n",
    "                   'מחלקות מייעצות': 'Advisory_Departments'}, inplace=True) # translating column names\n",
    "\n",
    "# Clean 'Diagnosis_In_Reception' & 'Diagnosis_In_Release' columns\n",
    "df.fillna({'Diagnosis_In_Reception': -1, 'Diagnosis_In_Release': -2}, inplace=True)\n",
    "\n",
    "fill_na_with_other_col(df, 'Diagnosis_In_Reception', 'Diagnosis_In_Release', fill_val=-1, reference_val=-2) \n",
    "fill_na_with_other_col(df, 'Diagnosis_In_Release', 'Diagnosis_In_Reception', fill_val=-2, reference_val=-1)\n",
    "\n",
    "# Clean 'Releasing_Doctor' column\n",
    "df['Releasing_Doctor'] = df['Releasing_Doctor'].fillna(-1)\n",
    "\n",
    "# Identify diagnosis categories and fill missing doctors\n",
    "diag_categories = get_diag_categories(df)\n",
    "doctor_map = {\n",
    "    cat: (df[df['Diagnosis_In_Release'].fillna('').astype(str).str.contains(cat)]['Releasing_Doctor'].mode().iloc[0]\n",
    "          if not df[df['Diagnosis_In_Release'].fillna('').astype(str).str.contains(cat)]['Releasing_Doctor'].mode().empty\n",
    "          else -1)\n",
    "    for cat in diag_categories\n",
    "}\n",
    "fill_missing_doctors(df, 'Diagnosis_In_Release', doctor_map)\n",
    "fill_missing_doctors(df, 'Diagnosis_In_Reception', doctor_map)\n",
    "\n",
    "# Clean 'Entry_Type' column and translate values\n",
    "df['Entry_Type'] = df['Entry_Type'].fillna('דחוף')\n",
    "translate_column(df, {'דחוף': 'urgent', 'מוזמן': 'scheduled', 'אשפוז יום': 'day hospitalization'}, 'Entry_Type')\n",
    "translate_column(df, {'ממרפאה': 'medical clinic', 'מבית חולים אחר': 'different hospital', \n",
    "                      'ממוסד': 'institude', 'מביתו': 'home', 'אחר': 'other'}, 'Patient_Origin')\n",
    "translate_column(df, {'שוחרר לביתו': 'home', 'שוחרר למוסד': 'institude'}, 'Release_Type')\n",
    "\n",
    "# Remove irrelevant columns and clean-up\n",
    "df.drop(columns=['Advisory_Departments'], inplace=True) # This column seems irrelevant for purposes, admission no releasing department is crucial\n",
    "df = df[~((df['Releasing_Doctor'] == -1) & (df['Diagnosis_In_Reception'] == -1) & (df['Diagnosis_In_Release'] == -1))]\n",
    "\n",
    "# Check for null values after cleaning\n",
    "print(\"Null values after cleaning:\")\n",
    "df.isnull().sum()"
   ],
   "id": "a7cf426a466f0f6a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values after cleaning:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Patient                      0\n",
       "unitName1                    0\n",
       "Admission_Medical_Record     0\n",
       "Admission_Entry_Date         0\n",
       "Release_Date                 0\n",
       "unitName2                    0\n",
       "Admission_Medical_Record2    0\n",
       "Admission_Entry_Date2        0\n",
       "Release_Date2                0\n",
       "Entry_Type                   0\n",
       "Patient_Origin               0\n",
       "Release_Type                 0\n",
       "Releasing_Doctor             0\n",
       "Admission_Days2              0\n",
       "Diagnosis_In_Reception       0\n",
       "Diagnosis_In_Release         0\n",
       "ct                           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-28T11:21:34.936839Z",
     "start_time": "2024-09-28T11:21:34.855116Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Calculate percentage of data loss\n",
    "final_row_count = df.shape[0]\n",
    "data_loss_percentage = ((initial_row_count - final_row_count) / initial_row_count) * 100\n",
    "print(f'Total samples after cleaning: {final_row_count}\\n')\n",
    "print(f'Percentage of data lost during cleaning: {data_loss_percentage:.2f}%\\n')\n",
    "\n",
    "# Date formatting and calculation\n",
    "df['Admission_Entry_Date'] = pd.to_datetime(df['Admission_Entry_Date'], format='%d/%m/%Y %H:%M')\n",
    "df['Release_Date'] = pd.to_datetime(df['Release_Date'], format='%d/%m/%Y %H:%M:%S')\n",
    "#df['Admission_Days'] = (df['Release_Date'] - df['Admission_Entry_Date']).dt.days.abs()\n",
    "\n",
    "# Categorize 'Days_Between_Admissions'\n",
    "df['Admission_Entry_Date2'] = pd.to_datetime(df['Admission_Entry_Date2'], format='%d/%m/%Y %H:%M')\n",
    "# df['Days_Between_Admissions'] = (df['Admission_Entry_Date2'] - df['Release_Date']).dt.days.abs()\n",
    "# bin_edges = calculate_optimal_split(df, 'Days_Between_Admissions', 3)\n",
    "# df['Period_Between_Admissions'] = pd.cut(df['Days_Between_Admissions'], bins=bin_edges, labels=['short', 'mid', 'long'])\n",
    "\n",
    "# Export cleaned data\n",
    "#df.drop(columns=['Admission_Medical_Record', 'Admission_Medical_Record2', 'Days_Between_Admissions'], inplace=True)\n",
    "df.to_csv(export_path, index=False)\n"
   ],
   "id": "d773c153af650f94",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples after cleaning: 8917\n",
      "\n",
      "Percentage of data lost during cleaning: 0.00%\n",
      "\n"
     ]
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can see that now the data contains no missing values and no rows were lost.",
   "id": "d98c906806f3409c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
